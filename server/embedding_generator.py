from typing import List, Union
from PIL import Image
from sentence_transformers import SentenceTransformer
import logging
from functools import lru_cache

# Configure logging
logger = logging.getLogger(__name__)

class EmbeddingGenerator:
    """
    Handles generation of embeddings for images and text using CLIP model.
    """
    
    def __init__(self, model_name: str = "clip-ViT-B-32"):
        """
        Initialize the embedding generator.
        
        Args:
            model_name: Name of the sentence-transformer model to use.
                        Default 'clip-ViT-B-32' is a good balance of speed/quality.
        """
        self.model_name = model_name
        logger.info(f"Loading embedding model: {model_name}")
        try:
            self.model = SentenceTransformer(model_name)
            logger.info("Model loaded successfully.")
        except Exception as e:
            logger.error(f"Failed to load model {model_name}: {e}")
            raise

    def generate_image_embedding(self, image: Image.Image) -> List[float]:
        """
        Generate embedding for a PIL Image.
        """
        try:
            # model.encode handles image preprocessing internally for CLIP models
            # We enforce normalization for Cosine Similarity compatibility
            embedding = self.model.encode(image, normalize_embeddings=True)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"Error generating image embedding: {e}")
            raise

    def generate_text_embedding(self, text: str) -> List[float]:
        """
        Generate embedding for a text query.
        """
        try:
            embedding = self.model.encode(text, normalize_embeddings=True)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"Error generating text embedding: {e}")
            raise

    @property
    def embedding_dimension(self) -> int:
        """
        Return the dimension of embeddings generated by this model.
        """
        return self.model.get_sentence_embedding_dimension()

# Global instance lazy loader pattern or singleton could be used here
# But for now we'll instantiate in main or where needed.
